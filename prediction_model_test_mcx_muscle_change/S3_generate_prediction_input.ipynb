{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'low_absorption'), exist_ok=True)\n",
    "os.makedirs(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'medium_absorption'), exist_ok=True)\n",
    "os.makedirs(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'high_absorption'), exist_ok=True)\n",
    "os.makedirs(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'all_absorption'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"OPs_used\", \"bloodConc.json\"), \"r\") as f:\n",
    "    bloodConc = json.load(f)\n",
    "    bloodConc = bloodConc['bloodConc']\n",
    "with open(os.path.join(\"OPs_used\", \"wavelength.json\"), 'r') as f:\n",
    "    wavelength = json.load(f)\n",
    "    wavelength = wavelength['wavelength']\n",
    "with open(os.path.join(\"OPs_used\", \"SO2.json\"), 'r') as f:\n",
    "    SO2 = json.load(f)\n",
    "    train_SO2 = SO2['train_SO2']\n",
    "    test_SO2 = SO2['test_SO2']\n",
    "with open(os.path.join('OPs_used', \"muscle_SO2.json\"), 'r') as f:\n",
    "    muscle_SO2 = json.load(f)\n",
    "    muscle_SO2 = muscle_SO2['SO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "based_ijv_SO2 = 0.7\n",
    "based_muscle_SO2 = 0.7\n",
    "prediction_input = {}\n",
    "\n",
    "for i in range(len(wavelength)):\n",
    "    prediction_input[f'T1_large_{wavelength[i]}nm'] = []\n",
    "for i in range(len(wavelength)):\n",
    "    prediction_input[f'T1_small_{wavelength[i]}nm'] = []\n",
    "for i in range(len(wavelength)):\n",
    "    prediction_input[f'T2_large_{wavelength[i]}nm'] = []\n",
    "for i in range(len(wavelength)):\n",
    "    prediction_input[f'T2_small_{wavelength[i]}nm'] = []\n",
    "prediction_input['blc'] = []\n",
    "prediction_input['ijv_SO2_change'] = []\n",
    "prediction_input['id'] = []\n",
    "prediction_input['muscle_SO2_change'] = []\n",
    "\n",
    "count = 0\n",
    "for wl_idx in range(len(wavelength)):\n",
    "    dataset_large = pd.read_csv(os.path.join('dataset', 'kb', 'kb_dataset_large', 'low', f'{wavelength[wl_idx]}nm_mus_{wl_idx+1}.csv'))\n",
    "    dataset_small = pd.read_csv(os.path.join('dataset', 'kb', 'kb_dataset_small', 'low', f'{wavelength[wl_idx]}nm_mus_{wl_idx+1}.csv'))\n",
    "    for blc in bloodConc:\n",
    "        for used_ijv_SO2 in test_SO2:\n",
    "            for used_muscle_SO2 in muscle_SO2:\n",
    "                if abs(used_ijv_SO2-based_ijv_SO2) < abs(used_muscle_SO2-based_muscle_SO2):\n",
    "                    continue\n",
    "                R_T1_large = dataset_large[(dataset_large['bloodConc']==blc) & (dataset_large['used_SO2']==based_ijv_SO2) & (dataset_large['muscle_SO2']==based_muscle_SO2)]\n",
    "                R_T1_large_SDS1 = R_T1_large['SDS_1']\n",
    "                R_T1_large_SDS2 = R_T1_large['SDS_11']\n",
    "                \n",
    "                R_T1_small = dataset_small[(dataset_small['bloodConc']==blc) & (dataset_small['used_SO2']==based_ijv_SO2) & (dataset_small['muscle_SO2']==based_muscle_SO2)]\n",
    "                R_T1_small_SDS1 = R_T1_small['SDS_1']\n",
    "                R_T1_small_SDS2 = R_T1_small['SDS_11']\n",
    "                \n",
    "                R_T2_large = dataset_large[(dataset_large['bloodConc']==blc) & (dataset_large['used_SO2']==used_ijv_SO2) & (dataset_large['muscle_SO2']==used_muscle_SO2)]\n",
    "                R_T2_large_SDS1 = R_T2_large['SDS_1']\n",
    "                R_T2_large_SDS2 = R_T2_large['SDS_11']\n",
    "                \n",
    "                R_T2_small = dataset_small[(dataset_small['bloodConc']==blc) & (dataset_small['used_SO2']==used_ijv_SO2) & (dataset_small['muscle_SO2']==used_muscle_SO2)]\n",
    "                R_T2_small_SDS1 = R_T2_small['SDS_1']\n",
    "                R_T2_small_SDS2 = R_T2_small['SDS_11']\n",
    "                \n",
    "                prediction_input[f'T1_large_{wavelength[wl_idx]}nm'] += list(R_T1_large_SDS1/R_T1_large_SDS2)\n",
    "                prediction_input[f'T1_small_{wavelength[wl_idx]}nm'] += list(R_T1_small_SDS1/R_T1_small_SDS2)\n",
    "                prediction_input[f'T2_large_{wavelength[wl_idx]}nm'] += list(R_T2_large_SDS1/R_T2_large_SDS2)\n",
    "                prediction_input[f'T2_small_{wavelength[wl_idx]}nm'] += list(R_T2_small_SDS1/R_T2_small_SDS2)\n",
    "                \n",
    "                # print(f'blc : {blc}, used_ijv_SO2 : {used_ijv_SO2}, used_muscle_SO2 : {used_muscle_SO2}, {R_T2.shape}')\n",
    "for blc in bloodConc:\n",
    "    for used_ijv_SO2 in test_SO2:\n",
    "        for used_muscle_SO2 in muscle_SO2:\n",
    "            if abs(used_ijv_SO2-based_ijv_SO2) < abs(used_muscle_SO2-based_muscle_SO2):\n",
    "                continue\n",
    "            prediction_input['blc'] += [blc]*20\n",
    "            prediction_input['ijv_SO2_change'] += [used_ijv_SO2]*20\n",
    "            prediction_input['id'] += [f'{count}_{i}' for i in range(20)]\n",
    "            count += 1\n",
    "            prediction_input['muscle_SO2_change'] += [used_muscle_SO2]*20\n",
    "\n",
    "\n",
    "prediction_input = pd.DataFrame(prediction_input)\n",
    "prediction_input.to_csv(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'all_absorption', 'prediction_input.csv'), index=False)\n",
    "all_prediction_input = prediction_input.to_numpy()\n",
    "np.save(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'all_absorption', 'prediction_input.npy'), all_prediction_input)\n",
    "condition = 10580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_input(prediction_input : pd, start : int, end : int):\n",
    "    data = []\n",
    "    count = 0\n",
    "    for i in range(condition):\n",
    "        for r in range(start, end):\n",
    "            if count == 0:\n",
    "                data = prediction_input[prediction_input['id']==f\"{i}_{r}\"]\n",
    "            else:\n",
    "                data = pd.concat((data, prediction_input[prediction_input['id']==f\"{i}_{r}\"]))\n",
    "            count += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = save_prediction_input(prediction_input, start=0, end=7)\n",
    "data.to_csv(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'high_absorption', 'prediction_input.csv'), index=False)\n",
    "data = data.to_numpy()\n",
    "np.save(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'high_absorption', 'prediction_input.npy'), data)\n",
    "\n",
    "data = save_prediction_input(prediction_input, start=7, end=14)\n",
    "data.to_csv(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'medium_absorption', 'prediction_input.csv'), index=False)\n",
    "data = data.to_numpy()\n",
    "np.save(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'medium_absorption', 'prediction_input.npy'), data)\n",
    "\n",
    "data = save_prediction_input(prediction_input, start=14, end=20)\n",
    "data.to_csv(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'low_absorption', 'prediction_input.csv'), index=False)\n",
    "data = data.to_numpy()\n",
    "np.save(os.path.join('dataset', 'kb', 'low_scatter_prediction_input', 'low_absorption', 'prediction_input.npy'), data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
